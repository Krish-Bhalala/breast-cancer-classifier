{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e460c1f-d676-4423-aa09-75aa0d9ba82f",
   "metadata": {},
   "source": [
    "# $\\color{RoyalBlue}{\\text{Breast Cancer Classifier}}$\n",
    "\n",
    "---\n",
    "\n",
    "**Author:** Krish S. Bhalala\n",
    "\n",
    "---\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "941b3837-7f63-4c68-b305-db68419aae70",
   "metadata": {},
   "source": [
    "#### Aknowledgment\n",
    "\n",
    "We will use the neuralnet library in R for creating and training artificial neural networks. In this assignment, I will use neuralnet to construct and train neural network models for classification tasks. This library provides a flexible framework for implementing various neural network architectures and offers tools for model evaluation and prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd1196e4-5d3a-4d54-b789-904839b63a34",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# library checks and installation\n",
    "if (!require(\"neuralnet\")) {\n",
    "  install.packages(\"neuralnet\")\n",
    "}\n",
    "library(neuralnet)\n",
    "\n",
    "if (!require(\"readr\")) {\n",
    "  install.packages(\"readr\")\n",
    "}\n",
    "library(readr)\n",
    "\n",
    "if (!require(\"dplyr\")) {\n",
    "  install.packages(\"dplyr\")\n",
    "}\n",
    "library(dplyr)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a49b298f-b487-4761-a22f-b49defb5e20f",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbbfdb4f-e193-4443-971e-cf0adc357991",
   "metadata": {},
   "source": [
    "## Introduction\n",
    "\n",
    "In this project, we will analyze a dataset related to breast cancer to predict whether a tumor is malignant (cancerous) or benign (non-cancerous). This prediction is crucial because it can significantly influence treatment decisions and patient outcomes.\n",
    "\n",
    "The dataset contains various features of tumors, such as size, shape, and texture. By examining these characteristics, we aim to build a model that can accurately classify tumors. This model will help healthcare professionals identify potential risks more effectively and provide timely interventions when necessary.\n",
    "\n",
    "Our approach will involve standard data preprocessing, model training, and evaluation to ensure that our predictions are reliable. Ultimately, our goal is to enhance the decision-making process in clinical settings, contributing to better patient care.\n",
    "\n",
    "## Understanding the Dataset\n",
    "\n",
    "First, let's take a look at our data. The Wisconsin Breast Cancer dataset is a valuable tool for studying breast cancer. It contains information about 569 breast masses, helping doctors and researchers better understand and predict cancer.\n",
    "\n",
    "Each mass in the dataset is described by 30 different measurements. These measurements tell us about the size, shape, and texture of the cells in the mass. For example:\n",
    "\n",
    "- Radius: How big the cells are\n",
    "- Texture: How smooth or rough the cells look\n",
    "- Perimeter: The distance around the cells\n",
    "- Area: How much space the cells take up\n",
    "- Smoothness: How even the cell edges are\n",
    "- Compactness: How dense or packed together the cells are\n",
    "- Concavity: How much the shape of the cells dips inward\n",
    "- Symmetry: How similar the two halves of the cells are\n",
    "\n",
    "These features help distinguish between normal cells and cancer cells. Cancer cells often look different from healthy cells - they might be larger, have irregular shapes, or be packed together differently.\n",
    "\n",
    "The most important part of this dataset is that each mass is labeled as either benign (not cancer) or malignant (cancer). This allows researchers to train computers to recognize patterns that might indicate cancer, potentially helping doctors make more accurate diagnoses in the future.\n",
    "\n",
    "By studying these features, scientists can develop better ways to detect breast cancer early, which is crucial for successful treatment\n",
    "\n",
    "## Data Preparation\n",
    "\n",
    "Let's start by loading the data and preparing it for our neural network. We will follow these steps in order.\n",
    "\n",
    "1. We're using three important libraries: neuralnet for creating our neural network, readr for reading the data file, and dplyr for data manipulation.\n",
    "\n",
    "2. We're loading the breast cancer data from a specific web address. This data doesn't have column names, so we're telling R not to expect them.\n",
    "\n",
    "3. Next, we're giving names to all the columns. The first column is \"id\", the second is \"diagnosis\", and the rest are named \"feature1\", \"feature2\", and so on up to \"feature30\".\n",
    "\n",
    "4. We're changing the \"diagnosis\" column from letters to numbers. \"M\" (for Malignant) becomes 1, and \"B\" (for Benign) becomes 0. This is because our neural network works better with numbers.\n",
    "\n",
    "5. We're removing the \"id\" column because it's not useful for predicting cancer.\n",
    "\n",
    "6. Finally, we're looking at the first few rows of our prepared data to make sure everything looks right.\n",
    "\n",
    "7. **NOTE:** *we are not checking for the NA values as the version of the dataset we selected assures there are no NA values in the dataset*.\n",
    "\n",
    "This preparation is crucial because it organizes our data in a way that our neural network can understand and use effectively for cancer prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c64ecc4e-5ccf-472d-9121-d2f77cf19b77",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 31</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>diagnosis</th><th scope=col>mean_radius</th><th scope=col>mean_texture</th><th scope=col>mean_perimeter</th><th scope=col>mean_area</th><th scope=col>mean_smoothness</th><th scope=col>mean_compactness</th><th scope=col>mean_concavity</th><th scope=col>mean_concave_points</th><th scope=col>mean_symmetry</th><th scope=col>⋯</th><th scope=col>worst_radius</th><th scope=col>worst_texture</th><th scope=col>worst_perimeter</th><th scope=col>worst_area</th><th scope=col>worst_smoothness</th><th scope=col>worst_compactness</th><th scope=col>worst_concavity</th><th scope=col>worst_concave_points</th><th scope=col>worst_symmetry</th><th scope=col>worst_fractal_dimension</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>17.99</td><td>10.38</td><td>122.80</td><td>1001.0</td><td>0.11840</td><td>0.27760</td><td>0.3001</td><td>0.14710</td><td>0.2419</td><td>⋯</td><td>25.38</td><td>17.33</td><td>184.60</td><td>2019.0</td><td>0.1622</td><td>0.6656</td><td>0.7119</td><td>0.2654</td><td>0.4601</td><td>0.11890</td></tr>\n",
       "\t<tr><td>1</td><td>20.57</td><td>17.77</td><td>132.90</td><td>1326.0</td><td>0.08474</td><td>0.07864</td><td>0.0869</td><td>0.07017</td><td>0.1812</td><td>⋯</td><td>24.99</td><td>23.41</td><td>158.80</td><td>1956.0</td><td>0.1238</td><td>0.1866</td><td>0.2416</td><td>0.1860</td><td>0.2750</td><td>0.08902</td></tr>\n",
       "\t<tr><td>1</td><td>19.69</td><td>21.25</td><td>130.00</td><td>1203.0</td><td>0.10960</td><td>0.15990</td><td>0.1974</td><td>0.12790</td><td>0.2069</td><td>⋯</td><td>23.57</td><td>25.53</td><td>152.50</td><td>1709.0</td><td>0.1444</td><td>0.4245</td><td>0.4504</td><td>0.2430</td><td>0.3613</td><td>0.08758</td></tr>\n",
       "\t<tr><td>1</td><td>11.42</td><td>20.38</td><td> 77.58</td><td> 386.1</td><td>0.14250</td><td>0.28390</td><td>0.2414</td><td>0.10520</td><td>0.2597</td><td>⋯</td><td>14.91</td><td>26.50</td><td> 98.87</td><td> 567.7</td><td>0.2098</td><td>0.8663</td><td>0.6869</td><td>0.2575</td><td>0.6638</td><td>0.17300</td></tr>\n",
       "\t<tr><td>1</td><td>20.29</td><td>14.34</td><td>135.10</td><td>1297.0</td><td>0.10030</td><td>0.13280</td><td>0.1980</td><td>0.10430</td><td>0.1809</td><td>⋯</td><td>22.54</td><td>16.67</td><td>152.20</td><td>1575.0</td><td>0.1374</td><td>0.2050</td><td>0.4000</td><td>0.1625</td><td>0.2364</td><td>0.07678</td></tr>\n",
       "\t<tr><td>1</td><td>12.45</td><td>15.70</td><td> 82.57</td><td> 477.1</td><td>0.12780</td><td>0.17000</td><td>0.1578</td><td>0.08089</td><td>0.2087</td><td>⋯</td><td>15.47</td><td>23.75</td><td>103.40</td><td> 741.6</td><td>0.1791</td><td>0.5249</td><td>0.5355</td><td>0.1741</td><td>0.3985</td><td>0.12440</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 31\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " diagnosis & mean\\_radius & mean\\_texture & mean\\_perimeter & mean\\_area & mean\\_smoothness & mean\\_compactness & mean\\_concavity & mean\\_concave\\_points & mean\\_symmetry & ⋯ & worst\\_radius & worst\\_texture & worst\\_perimeter & worst\\_area & worst\\_smoothness & worst\\_compactness & worst\\_concavity & worst\\_concave\\_points & worst\\_symmetry & worst\\_fractal\\_dimension\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & 17.99 & 10.38 & 122.80 & 1001.0 & 0.11840 & 0.27760 & 0.3001 & 0.14710 & 0.2419 & ⋯ & 25.38 & 17.33 & 184.60 & 2019.0 & 0.1622 & 0.6656 & 0.7119 & 0.2654 & 0.4601 & 0.11890\\\\\n",
       "\t 1 & 20.57 & 17.77 & 132.90 & 1326.0 & 0.08474 & 0.07864 & 0.0869 & 0.07017 & 0.1812 & ⋯ & 24.99 & 23.41 & 158.80 & 1956.0 & 0.1238 & 0.1866 & 0.2416 & 0.1860 & 0.2750 & 0.08902\\\\\n",
       "\t 1 & 19.69 & 21.25 & 130.00 & 1203.0 & 0.10960 & 0.15990 & 0.1974 & 0.12790 & 0.2069 & ⋯ & 23.57 & 25.53 & 152.50 & 1709.0 & 0.1444 & 0.4245 & 0.4504 & 0.2430 & 0.3613 & 0.08758\\\\\n",
       "\t 1 & 11.42 & 20.38 &  77.58 &  386.1 & 0.14250 & 0.28390 & 0.2414 & 0.10520 & 0.2597 & ⋯ & 14.91 & 26.50 &  98.87 &  567.7 & 0.2098 & 0.8663 & 0.6869 & 0.2575 & 0.6638 & 0.17300\\\\\n",
       "\t 1 & 20.29 & 14.34 & 135.10 & 1297.0 & 0.10030 & 0.13280 & 0.1980 & 0.10430 & 0.1809 & ⋯ & 22.54 & 16.67 & 152.20 & 1575.0 & 0.1374 & 0.2050 & 0.4000 & 0.1625 & 0.2364 & 0.07678\\\\\n",
       "\t 1 & 12.45 & 15.70 &  82.57 &  477.1 & 0.12780 & 0.17000 & 0.1578 & 0.08089 & 0.2087 & ⋯ & 15.47 & 23.75 & 103.40 &  741.6 & 0.1791 & 0.5249 & 0.5355 & 0.1741 & 0.3985 & 0.12440\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 31\n",
       "\n",
       "| diagnosis &lt;fct&gt; | mean_radius &lt;dbl&gt; | mean_texture &lt;dbl&gt; | mean_perimeter &lt;dbl&gt; | mean_area &lt;dbl&gt; | mean_smoothness &lt;dbl&gt; | mean_compactness &lt;dbl&gt; | mean_concavity &lt;dbl&gt; | mean_concave_points &lt;dbl&gt; | mean_symmetry &lt;dbl&gt; | ⋯ ⋯ | worst_radius &lt;dbl&gt; | worst_texture &lt;dbl&gt; | worst_perimeter &lt;dbl&gt; | worst_area &lt;dbl&gt; | worst_smoothness &lt;dbl&gt; | worst_compactness &lt;dbl&gt; | worst_concavity &lt;dbl&gt; | worst_concave_points &lt;dbl&gt; | worst_symmetry &lt;dbl&gt; | worst_fractal_dimension &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 17.99 | 10.38 | 122.80 | 1001.0 | 0.11840 | 0.27760 | 0.3001 | 0.14710 | 0.2419 | ⋯ | 25.38 | 17.33 | 184.60 | 2019.0 | 0.1622 | 0.6656 | 0.7119 | 0.2654 | 0.4601 | 0.11890 |\n",
       "| 1 | 20.57 | 17.77 | 132.90 | 1326.0 | 0.08474 | 0.07864 | 0.0869 | 0.07017 | 0.1812 | ⋯ | 24.99 | 23.41 | 158.80 | 1956.0 | 0.1238 | 0.1866 | 0.2416 | 0.1860 | 0.2750 | 0.08902 |\n",
       "| 1 | 19.69 | 21.25 | 130.00 | 1203.0 | 0.10960 | 0.15990 | 0.1974 | 0.12790 | 0.2069 | ⋯ | 23.57 | 25.53 | 152.50 | 1709.0 | 0.1444 | 0.4245 | 0.4504 | 0.2430 | 0.3613 | 0.08758 |\n",
       "| 1 | 11.42 | 20.38 |  77.58 |  386.1 | 0.14250 | 0.28390 | 0.2414 | 0.10520 | 0.2597 | ⋯ | 14.91 | 26.50 |  98.87 |  567.7 | 0.2098 | 0.8663 | 0.6869 | 0.2575 | 0.6638 | 0.17300 |\n",
       "| 1 | 20.29 | 14.34 | 135.10 | 1297.0 | 0.10030 | 0.13280 | 0.1980 | 0.10430 | 0.1809 | ⋯ | 22.54 | 16.67 | 152.20 | 1575.0 | 0.1374 | 0.2050 | 0.4000 | 0.1625 | 0.2364 | 0.07678 |\n",
       "| 1 | 12.45 | 15.70 |  82.57 |  477.1 | 0.12780 | 0.17000 | 0.1578 | 0.08089 | 0.2087 | ⋯ | 15.47 | 23.75 | 103.40 |  741.6 | 0.1791 | 0.5249 | 0.5355 | 0.1741 | 0.3985 | 0.12440 |\n",
       "\n"
      ],
      "text/plain": [
       "  diagnosis mean_radius mean_texture mean_perimeter mean_area mean_smoothness\n",
       "1 1         17.99       10.38        122.80         1001.0    0.11840        \n",
       "2 1         20.57       17.77        132.90         1326.0    0.08474        \n",
       "3 1         19.69       21.25        130.00         1203.0    0.10960        \n",
       "4 1         11.42       20.38         77.58          386.1    0.14250        \n",
       "5 1         20.29       14.34        135.10         1297.0    0.10030        \n",
       "6 1         12.45       15.70         82.57          477.1    0.12780        \n",
       "  mean_compactness mean_concavity mean_concave_points mean_symmetry ⋯\n",
       "1 0.27760          0.3001         0.14710             0.2419        ⋯\n",
       "2 0.07864          0.0869         0.07017             0.1812        ⋯\n",
       "3 0.15990          0.1974         0.12790             0.2069        ⋯\n",
       "4 0.28390          0.2414         0.10520             0.2597        ⋯\n",
       "5 0.13280          0.1980         0.10430             0.1809        ⋯\n",
       "6 0.17000          0.1578         0.08089             0.2087        ⋯\n",
       "  worst_radius worst_texture worst_perimeter worst_area worst_smoothness\n",
       "1 25.38        17.33         184.60          2019.0     0.1622          \n",
       "2 24.99        23.41         158.80          1956.0     0.1238          \n",
       "3 23.57        25.53         152.50          1709.0     0.1444          \n",
       "4 14.91        26.50          98.87           567.7     0.2098          \n",
       "5 22.54        16.67         152.20          1575.0     0.1374          \n",
       "6 15.47        23.75         103.40           741.6     0.1791          \n",
       "  worst_compactness worst_concavity worst_concave_points worst_symmetry\n",
       "1 0.6656            0.7119          0.2654               0.4601        \n",
       "2 0.1866            0.2416          0.1860               0.2750        \n",
       "3 0.4245            0.4504          0.2430               0.3613        \n",
       "4 0.8663            0.6869          0.2575               0.6638        \n",
       "5 0.2050            0.4000          0.1625               0.2364        \n",
       "6 0.5249            0.5355          0.1741               0.3985        \n",
       "  worst_fractal_dimension\n",
       "1 0.11890                \n",
       "2 0.08902                \n",
       "3 0.08758                \n",
       "4 0.17300                \n",
       "5 0.07678                \n",
       "6 0.12440                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the data\n",
    "data = read_csv(\"https://archive.ics.uci.edu/ml/machine-learning-databases/breast-cancer-wisconsin/wdbc.data\", \n",
    "                 col_names = FALSE,\n",
    "                 show_col_types = FALSE)\n",
    "\n",
    "# Assign column names\n",
    "colnames(data) = c(\"id\", \"diagnosis\", \n",
    "                    \"mean_radius\", \"mean_texture\", \"mean_perimeter\", \"mean_area\", \"mean_smoothness\", \n",
    "                    \"mean_compactness\", \"mean_concavity\", \"mean_concave_points\", \"mean_symmetry\", \"mean_fractal_dimension\",\n",
    "                    \"se_radius\", \"se_texture\", \"se_perimeter\", \"se_area\", \"se_smoothness\", \n",
    "                    \"se_compactness\", \"se_concavity\", \"se_concave_points\", \"se_symmetry\", \"se_fractal_dimension\",\n",
    "                    \"worst_radius\", \"worst_texture\", \"worst_perimeter\", \"worst_area\", \"worst_smoothness\", \n",
    "                    \"worst_compactness\", \"worst_concavity\", \"worst_concave_points\", \"worst_symmetry\", \"worst_fractal_dimension\")\n",
    "\n",
    "# Convert diagnosis to numeric (0 for Benign, 1 for Malignant)\n",
    "data$diagnosis = ifelse(data$diagnosis == \"M\", 1, 0)\n",
    "\n",
    "# Assuming 'diagnosis' is your response variable\n",
    "data$diagnosis <- as.factor(data$diagnosis)\n",
    "\n",
    "# Remove the ID column as it's not needed for prediction\n",
    "data = data[, -1]\n",
    "\n",
    "head(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21bbd4bf-705f-48d8-a9a7-ec9a5ec4641a",
   "metadata": {},
   "source": [
    "Here, we've loaded the data and done some basic preprocessing. We've changed the 'diagnosis' column to numbers (0 for benign, 1 for malignant) because our neural network works better with numbers.\n",
    "\n",
    "## Creating Training and Testing Sets\n",
    "\n",
    "Now, we will split our dataset into training and testing sets. This step is essential for developing a reliable model. We will use the training set to teach our model the underlying patterns in the data, while the testing set will allow us to evaluate its performance on unseen data.\n",
    "\n",
    "We will typically allocate about 70-80% of the data for training and reserve the remaining 20-30% for testing. This random selection ensures that both sets are representative of the overall dataset. By doing this, we can assess how well our model generalizes to new cases.\n",
    "\n",
    "Once we have completed this split, we will proceed to train our neural network using the training data. After training, we will evaluate the model's accuracy using the testing set to determine its effectiveness in predicting breast cancer outcomes. This systematic approach will help us build a robust predictive tool that can assist in clinical decision-making."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "63f301e2-17b0-406c-8dbf-92001cea301a",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 31</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>diagnosis</th><th scope=col>mean_radius</th><th scope=col>mean_texture</th><th scope=col>mean_perimeter</th><th scope=col>mean_area</th><th scope=col>mean_smoothness</th><th scope=col>mean_compactness</th><th scope=col>mean_concavity</th><th scope=col>mean_concave_points</th><th scope=col>mean_symmetry</th><th scope=col>⋯</th><th scope=col>worst_radius</th><th scope=col>worst_texture</th><th scope=col>worst_perimeter</th><th scope=col>worst_area</th><th scope=col>worst_smoothness</th><th scope=col>worst_compactness</th><th scope=col>worst_concavity</th><th scope=col>worst_concave_points</th><th scope=col>worst_symmetry</th><th scope=col>worst_fractal_dimension</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>13.61</td><td>24.98</td><td> 88.05</td><td> 582.7</td><td>0.09488</td><td>0.08511</td><td>0.08625</td><td>0.04489</td><td>0.1609</td><td>⋯</td><td>16.99</td><td>35.27</td><td>108.6</td><td> 906.5</td><td>0.1265</td><td>0.1943</td><td>0.31690</td><td>0.11840</td><td>0.2651</td><td>0.07397</td></tr>\n",
       "\t<tr><td>0</td><td>14.97</td><td>16.95</td><td> 96.22</td><td> 685.9</td><td>0.09855</td><td>0.07885</td><td>0.02602</td><td>0.03781</td><td>0.1780</td><td>⋯</td><td>16.11</td><td>23.00</td><td>104.6</td><td> 793.7</td><td>0.1216</td><td>0.1637</td><td>0.06648</td><td>0.08485</td><td>0.2404</td><td>0.06428</td></tr>\n",
       "\t<tr><td>1</td><td>27.42</td><td>26.27</td><td>186.90</td><td>2501.0</td><td>0.10840</td><td>0.19880</td><td>0.36350</td><td>0.16890</td><td>0.2061</td><td>⋯</td><td>36.04</td><td>31.37</td><td>251.2</td><td>4254.0</td><td>0.1357</td><td>0.4256</td><td>0.68330</td><td>0.26250</td><td>0.2641</td><td>0.07427</td></tr>\n",
       "\t<tr><td>0</td><td>16.17</td><td>16.07</td><td>106.30</td><td> 788.5</td><td>0.09880</td><td>0.14380</td><td>0.06651</td><td>0.05397</td><td>0.1990</td><td>⋯</td><td>16.97</td><td>19.14</td><td>113.1</td><td> 861.5</td><td>0.1235</td><td>0.2550</td><td>0.21140</td><td>0.12510</td><td>0.3153</td><td>0.08960</td></tr>\n",
       "\t<tr><td>1</td><td>17.20</td><td>24.52</td><td>114.20</td><td> 929.4</td><td>0.10710</td><td>0.18300</td><td>0.16920</td><td>0.07944</td><td>0.1927</td><td>⋯</td><td>23.32</td><td>33.82</td><td>151.6</td><td>1681.0</td><td>0.1585</td><td>0.7394</td><td>0.65660</td><td>0.18990</td><td>0.3313</td><td>0.13390</td></tr>\n",
       "\t<tr><td>1</td><td>23.27</td><td>22.04</td><td>152.10</td><td>1686.0</td><td>0.08439</td><td>0.11450</td><td>0.13240</td><td>0.09702</td><td>0.1801</td><td>⋯</td><td>28.01</td><td>28.22</td><td>184.2</td><td>2403.0</td><td>0.1228</td><td>0.3583</td><td>0.39480</td><td>0.23460</td><td>0.3589</td><td>0.09187</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 31\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " diagnosis & mean\\_radius & mean\\_texture & mean\\_perimeter & mean\\_area & mean\\_smoothness & mean\\_compactness & mean\\_concavity & mean\\_concave\\_points & mean\\_symmetry & ⋯ & worst\\_radius & worst\\_texture & worst\\_perimeter & worst\\_area & worst\\_smoothness & worst\\_compactness & worst\\_concavity & worst\\_concave\\_points & worst\\_symmetry & worst\\_fractal\\_dimension\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & 13.61 & 24.98 &  88.05 &  582.7 & 0.09488 & 0.08511 & 0.08625 & 0.04489 & 0.1609 & ⋯ & 16.99 & 35.27 & 108.6 &  906.5 & 0.1265 & 0.1943 & 0.31690 & 0.11840 & 0.2651 & 0.07397\\\\\n",
       "\t 0 & 14.97 & 16.95 &  96.22 &  685.9 & 0.09855 & 0.07885 & 0.02602 & 0.03781 & 0.1780 & ⋯ & 16.11 & 23.00 & 104.6 &  793.7 & 0.1216 & 0.1637 & 0.06648 & 0.08485 & 0.2404 & 0.06428\\\\\n",
       "\t 1 & 27.42 & 26.27 & 186.90 & 2501.0 & 0.10840 & 0.19880 & 0.36350 & 0.16890 & 0.2061 & ⋯ & 36.04 & 31.37 & 251.2 & 4254.0 & 0.1357 & 0.4256 & 0.68330 & 0.26250 & 0.2641 & 0.07427\\\\\n",
       "\t 0 & 16.17 & 16.07 & 106.30 &  788.5 & 0.09880 & 0.14380 & 0.06651 & 0.05397 & 0.1990 & ⋯ & 16.97 & 19.14 & 113.1 &  861.5 & 0.1235 & 0.2550 & 0.21140 & 0.12510 & 0.3153 & 0.08960\\\\\n",
       "\t 1 & 17.20 & 24.52 & 114.20 &  929.4 & 0.10710 & 0.18300 & 0.16920 & 0.07944 & 0.1927 & ⋯ & 23.32 & 33.82 & 151.6 & 1681.0 & 0.1585 & 0.7394 & 0.65660 & 0.18990 & 0.3313 & 0.13390\\\\\n",
       "\t 1 & 23.27 & 22.04 & 152.10 & 1686.0 & 0.08439 & 0.11450 & 0.13240 & 0.09702 & 0.1801 & ⋯ & 28.01 & 28.22 & 184.2 & 2403.0 & 0.1228 & 0.3583 & 0.39480 & 0.23460 & 0.3589 & 0.09187\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 31\n",
       "\n",
       "| diagnosis &lt;fct&gt; | mean_radius &lt;dbl&gt; | mean_texture &lt;dbl&gt; | mean_perimeter &lt;dbl&gt; | mean_area &lt;dbl&gt; | mean_smoothness &lt;dbl&gt; | mean_compactness &lt;dbl&gt; | mean_concavity &lt;dbl&gt; | mean_concave_points &lt;dbl&gt; | mean_symmetry &lt;dbl&gt; | ⋯ ⋯ | worst_radius &lt;dbl&gt; | worst_texture &lt;dbl&gt; | worst_perimeter &lt;dbl&gt; | worst_area &lt;dbl&gt; | worst_smoothness &lt;dbl&gt; | worst_compactness &lt;dbl&gt; | worst_concavity &lt;dbl&gt; | worst_concave_points &lt;dbl&gt; | worst_symmetry &lt;dbl&gt; | worst_fractal_dimension &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 13.61 | 24.98 |  88.05 |  582.7 | 0.09488 | 0.08511 | 0.08625 | 0.04489 | 0.1609 | ⋯ | 16.99 | 35.27 | 108.6 |  906.5 | 0.1265 | 0.1943 | 0.31690 | 0.11840 | 0.2651 | 0.07397 |\n",
       "| 0 | 14.97 | 16.95 |  96.22 |  685.9 | 0.09855 | 0.07885 | 0.02602 | 0.03781 | 0.1780 | ⋯ | 16.11 | 23.00 | 104.6 |  793.7 | 0.1216 | 0.1637 | 0.06648 | 0.08485 | 0.2404 | 0.06428 |\n",
       "| 1 | 27.42 | 26.27 | 186.90 | 2501.0 | 0.10840 | 0.19880 | 0.36350 | 0.16890 | 0.2061 | ⋯ | 36.04 | 31.37 | 251.2 | 4254.0 | 0.1357 | 0.4256 | 0.68330 | 0.26250 | 0.2641 | 0.07427 |\n",
       "| 0 | 16.17 | 16.07 | 106.30 |  788.5 | 0.09880 | 0.14380 | 0.06651 | 0.05397 | 0.1990 | ⋯ | 16.97 | 19.14 | 113.1 |  861.5 | 0.1235 | 0.2550 | 0.21140 | 0.12510 | 0.3153 | 0.08960 |\n",
       "| 1 | 17.20 | 24.52 | 114.20 |  929.4 | 0.10710 | 0.18300 | 0.16920 | 0.07944 | 0.1927 | ⋯ | 23.32 | 33.82 | 151.6 | 1681.0 | 0.1585 | 0.7394 | 0.65660 | 0.18990 | 0.3313 | 0.13390 |\n",
       "| 1 | 23.27 | 22.04 | 152.10 | 1686.0 | 0.08439 | 0.11450 | 0.13240 | 0.09702 | 0.1801 | ⋯ | 28.01 | 28.22 | 184.2 | 2403.0 | 0.1228 | 0.3583 | 0.39480 | 0.23460 | 0.3589 | 0.09187 |\n",
       "\n"
      ],
      "text/plain": [
       "  diagnosis mean_radius mean_texture mean_perimeter mean_area mean_smoothness\n",
       "1 1         13.61       24.98         88.05          582.7    0.09488        \n",
       "2 0         14.97       16.95         96.22          685.9    0.09855        \n",
       "3 1         27.42       26.27        186.90         2501.0    0.10840        \n",
       "4 0         16.17       16.07        106.30          788.5    0.09880        \n",
       "5 1         17.20       24.52        114.20          929.4    0.10710        \n",
       "6 1         23.27       22.04        152.10         1686.0    0.08439        \n",
       "  mean_compactness mean_concavity mean_concave_points mean_symmetry ⋯\n",
       "1 0.08511          0.08625        0.04489             0.1609        ⋯\n",
       "2 0.07885          0.02602        0.03781             0.1780        ⋯\n",
       "3 0.19880          0.36350        0.16890             0.2061        ⋯\n",
       "4 0.14380          0.06651        0.05397             0.1990        ⋯\n",
       "5 0.18300          0.16920        0.07944             0.1927        ⋯\n",
       "6 0.11450          0.13240        0.09702             0.1801        ⋯\n",
       "  worst_radius worst_texture worst_perimeter worst_area worst_smoothness\n",
       "1 16.99        35.27         108.6            906.5     0.1265          \n",
       "2 16.11        23.00         104.6            793.7     0.1216          \n",
       "3 36.04        31.37         251.2           4254.0     0.1357          \n",
       "4 16.97        19.14         113.1            861.5     0.1235          \n",
       "5 23.32        33.82         151.6           1681.0     0.1585          \n",
       "6 28.01        28.22         184.2           2403.0     0.1228          \n",
       "  worst_compactness worst_concavity worst_concave_points worst_symmetry\n",
       "1 0.1943            0.31690         0.11840              0.2651        \n",
       "2 0.1637            0.06648         0.08485              0.2404        \n",
       "3 0.4256            0.68330         0.26250              0.2641        \n",
       "4 0.2550            0.21140         0.12510              0.3153        \n",
       "5 0.7394            0.65660         0.18990              0.3313        \n",
       "6 0.3583            0.39480         0.23460              0.3589        \n",
       "  worst_fractal_dimension\n",
       "1 0.07397                \n",
       "2 0.06428                \n",
       "3 0.07427                \n",
       "4 0.08960                \n",
       "5 0.13390                \n",
       "6 0.09187                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set a seed for reproducibility\n",
    "set.seed(420)\n",
    "\n",
    "# Create index for splitting\n",
    "split_index = sample(1:nrow(data), 0.7 * nrow(data))\n",
    "\n",
    "# Create training and testing sets\n",
    "train_data = data[split_index, ]\n",
    "head(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "0848caaf-c4e5-44bf-a3cc-22b47dbaf7de",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 6 × 31</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>diagnosis</th><th scope=col>mean_radius</th><th scope=col>mean_texture</th><th scope=col>mean_perimeter</th><th scope=col>mean_area</th><th scope=col>mean_smoothness</th><th scope=col>mean_compactness</th><th scope=col>mean_concavity</th><th scope=col>mean_concave_points</th><th scope=col>mean_symmetry</th><th scope=col>⋯</th><th scope=col>worst_radius</th><th scope=col>worst_texture</th><th scope=col>worst_perimeter</th><th scope=col>worst_area</th><th scope=col>worst_smoothness</th><th scope=col>worst_compactness</th><th scope=col>worst_concavity</th><th scope=col>worst_concave_points</th><th scope=col>worst_symmetry</th><th scope=col>worst_fractal_dimension</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>⋯</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>11.42</td><td>20.38</td><td> 77.58</td><td> 386.1</td><td>0.14250</td><td>0.28390</td><td>0.24140</td><td>0.10520</td><td>0.2597</td><td>⋯</td><td>14.91</td><td>26.50</td><td> 98.87</td><td> 567.7</td><td>0.2098</td><td>0.8663</td><td>0.6869</td><td>0.25750</td><td>0.6638</td><td>0.17300</td></tr>\n",
       "\t<tr><td>1</td><td>20.29</td><td>14.34</td><td>135.10</td><td>1297.0</td><td>0.10030</td><td>0.13280</td><td>0.19800</td><td>0.10430</td><td>0.1809</td><td>⋯</td><td>22.54</td><td>16.67</td><td>152.20</td><td>1575.0</td><td>0.1374</td><td>0.2050</td><td>0.4000</td><td>0.16250</td><td>0.2364</td><td>0.07678</td></tr>\n",
       "\t<tr><td>1</td><td>12.45</td><td>15.70</td><td> 82.57</td><td> 477.1</td><td>0.12780</td><td>0.17000</td><td>0.15780</td><td>0.08089</td><td>0.2087</td><td>⋯</td><td>15.47</td><td>23.75</td><td>103.40</td><td> 741.6</td><td>0.1791</td><td>0.5249</td><td>0.5355</td><td>0.17410</td><td>0.3985</td><td>0.12440</td></tr>\n",
       "\t<tr><td>1</td><td>16.02</td><td>23.24</td><td>102.70</td><td> 797.8</td><td>0.08206</td><td>0.06669</td><td>0.03299</td><td>0.03323</td><td>0.1528</td><td>⋯</td><td>19.19</td><td>33.88</td><td>123.80</td><td>1150.0</td><td>0.1181</td><td>0.1551</td><td>0.1459</td><td>0.09975</td><td>0.2948</td><td>0.08452</td></tr>\n",
       "\t<tr><td>1</td><td>15.78</td><td>17.89</td><td>103.60</td><td> 781.0</td><td>0.09710</td><td>0.12920</td><td>0.09954</td><td>0.06606</td><td>0.1842</td><td>⋯</td><td>20.42</td><td>27.28</td><td>136.50</td><td>1299.0</td><td>0.1396</td><td>0.5609</td><td>0.3965</td><td>0.18100</td><td>0.3792</td><td>0.10480</td></tr>\n",
       "\t<tr><td>1</td><td>19.17</td><td>24.80</td><td>132.40</td><td>1123.0</td><td>0.09740</td><td>0.24580</td><td>0.20650</td><td>0.11180</td><td>0.2397</td><td>⋯</td><td>20.96</td><td>29.94</td><td>151.70</td><td>1332.0</td><td>0.1037</td><td>0.3903</td><td>0.3639</td><td>0.17670</td><td>0.3176</td><td>0.10230</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 6 × 31\n",
       "\\begin{tabular}{lllllllllllllllllllll}\n",
       " diagnosis & mean\\_radius & mean\\_texture & mean\\_perimeter & mean\\_area & mean\\_smoothness & mean\\_compactness & mean\\_concavity & mean\\_concave\\_points & mean\\_symmetry & ⋯ & worst\\_radius & worst\\_texture & worst\\_perimeter & worst\\_area & worst\\_smoothness & worst\\_compactness & worst\\_concavity & worst\\_concave\\_points & worst\\_symmetry & worst\\_fractal\\_dimension\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & ⋯ & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 1 & 11.42 & 20.38 &  77.58 &  386.1 & 0.14250 & 0.28390 & 0.24140 & 0.10520 & 0.2597 & ⋯ & 14.91 & 26.50 &  98.87 &  567.7 & 0.2098 & 0.8663 & 0.6869 & 0.25750 & 0.6638 & 0.17300\\\\\n",
       "\t 1 & 20.29 & 14.34 & 135.10 & 1297.0 & 0.10030 & 0.13280 & 0.19800 & 0.10430 & 0.1809 & ⋯ & 22.54 & 16.67 & 152.20 & 1575.0 & 0.1374 & 0.2050 & 0.4000 & 0.16250 & 0.2364 & 0.07678\\\\\n",
       "\t 1 & 12.45 & 15.70 &  82.57 &  477.1 & 0.12780 & 0.17000 & 0.15780 & 0.08089 & 0.2087 & ⋯ & 15.47 & 23.75 & 103.40 &  741.6 & 0.1791 & 0.5249 & 0.5355 & 0.17410 & 0.3985 & 0.12440\\\\\n",
       "\t 1 & 16.02 & 23.24 & 102.70 &  797.8 & 0.08206 & 0.06669 & 0.03299 & 0.03323 & 0.1528 & ⋯ & 19.19 & 33.88 & 123.80 & 1150.0 & 0.1181 & 0.1551 & 0.1459 & 0.09975 & 0.2948 & 0.08452\\\\\n",
       "\t 1 & 15.78 & 17.89 & 103.60 &  781.0 & 0.09710 & 0.12920 & 0.09954 & 0.06606 & 0.1842 & ⋯ & 20.42 & 27.28 & 136.50 & 1299.0 & 0.1396 & 0.5609 & 0.3965 & 0.18100 & 0.3792 & 0.10480\\\\\n",
       "\t 1 & 19.17 & 24.80 & 132.40 & 1123.0 & 0.09740 & 0.24580 & 0.20650 & 0.11180 & 0.2397 & ⋯ & 20.96 & 29.94 & 151.70 & 1332.0 & 0.1037 & 0.3903 & 0.3639 & 0.17670 & 0.3176 & 0.10230\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 6 × 31\n",
       "\n",
       "| diagnosis &lt;fct&gt; | mean_radius &lt;dbl&gt; | mean_texture &lt;dbl&gt; | mean_perimeter &lt;dbl&gt; | mean_area &lt;dbl&gt; | mean_smoothness &lt;dbl&gt; | mean_compactness &lt;dbl&gt; | mean_concavity &lt;dbl&gt; | mean_concave_points &lt;dbl&gt; | mean_symmetry &lt;dbl&gt; | ⋯ ⋯ | worst_radius &lt;dbl&gt; | worst_texture &lt;dbl&gt; | worst_perimeter &lt;dbl&gt; | worst_area &lt;dbl&gt; | worst_smoothness &lt;dbl&gt; | worst_compactness &lt;dbl&gt; | worst_concavity &lt;dbl&gt; | worst_concave_points &lt;dbl&gt; | worst_symmetry &lt;dbl&gt; | worst_fractal_dimension &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|---|\n",
       "| 1 | 11.42 | 20.38 |  77.58 |  386.1 | 0.14250 | 0.28390 | 0.24140 | 0.10520 | 0.2597 | ⋯ | 14.91 | 26.50 |  98.87 |  567.7 | 0.2098 | 0.8663 | 0.6869 | 0.25750 | 0.6638 | 0.17300 |\n",
       "| 1 | 20.29 | 14.34 | 135.10 | 1297.0 | 0.10030 | 0.13280 | 0.19800 | 0.10430 | 0.1809 | ⋯ | 22.54 | 16.67 | 152.20 | 1575.0 | 0.1374 | 0.2050 | 0.4000 | 0.16250 | 0.2364 | 0.07678 |\n",
       "| 1 | 12.45 | 15.70 |  82.57 |  477.1 | 0.12780 | 0.17000 | 0.15780 | 0.08089 | 0.2087 | ⋯ | 15.47 | 23.75 | 103.40 |  741.6 | 0.1791 | 0.5249 | 0.5355 | 0.17410 | 0.3985 | 0.12440 |\n",
       "| 1 | 16.02 | 23.24 | 102.70 |  797.8 | 0.08206 | 0.06669 | 0.03299 | 0.03323 | 0.1528 | ⋯ | 19.19 | 33.88 | 123.80 | 1150.0 | 0.1181 | 0.1551 | 0.1459 | 0.09975 | 0.2948 | 0.08452 |\n",
       "| 1 | 15.78 | 17.89 | 103.60 |  781.0 | 0.09710 | 0.12920 | 0.09954 | 0.06606 | 0.1842 | ⋯ | 20.42 | 27.28 | 136.50 | 1299.0 | 0.1396 | 0.5609 | 0.3965 | 0.18100 | 0.3792 | 0.10480 |\n",
       "| 1 | 19.17 | 24.80 | 132.40 | 1123.0 | 0.09740 | 0.24580 | 0.20650 | 0.11180 | 0.2397 | ⋯ | 20.96 | 29.94 | 151.70 | 1332.0 | 0.1037 | 0.3903 | 0.3639 | 0.17670 | 0.3176 | 0.10230 |\n",
       "\n"
      ],
      "text/plain": [
       "  diagnosis mean_radius mean_texture mean_perimeter mean_area mean_smoothness\n",
       "1 1         11.42       20.38         77.58          386.1    0.14250        \n",
       "2 1         20.29       14.34        135.10         1297.0    0.10030        \n",
       "3 1         12.45       15.70         82.57          477.1    0.12780        \n",
       "4 1         16.02       23.24        102.70          797.8    0.08206        \n",
       "5 1         15.78       17.89        103.60          781.0    0.09710        \n",
       "6 1         19.17       24.80        132.40         1123.0    0.09740        \n",
       "  mean_compactness mean_concavity mean_concave_points mean_symmetry ⋯\n",
       "1 0.28390          0.24140        0.10520             0.2597        ⋯\n",
       "2 0.13280          0.19800        0.10430             0.1809        ⋯\n",
       "3 0.17000          0.15780        0.08089             0.2087        ⋯\n",
       "4 0.06669          0.03299        0.03323             0.1528        ⋯\n",
       "5 0.12920          0.09954        0.06606             0.1842        ⋯\n",
       "6 0.24580          0.20650        0.11180             0.2397        ⋯\n",
       "  worst_radius worst_texture worst_perimeter worst_area worst_smoothness\n",
       "1 14.91        26.50          98.87           567.7     0.2098          \n",
       "2 22.54        16.67         152.20          1575.0     0.1374          \n",
       "3 15.47        23.75         103.40           741.6     0.1791          \n",
       "4 19.19        33.88         123.80          1150.0     0.1181          \n",
       "5 20.42        27.28         136.50          1299.0     0.1396          \n",
       "6 20.96        29.94         151.70          1332.0     0.1037          \n",
       "  worst_compactness worst_concavity worst_concave_points worst_symmetry\n",
       "1 0.8663            0.6869          0.25750              0.6638        \n",
       "2 0.2050            0.4000          0.16250              0.2364        \n",
       "3 0.5249            0.5355          0.17410              0.3985        \n",
       "4 0.1551            0.1459          0.09975              0.2948        \n",
       "5 0.5609            0.3965          0.18100              0.3792        \n",
       "6 0.3903            0.3639          0.17670              0.3176        \n",
       "  worst_fractal_dimension\n",
       "1 0.17300                \n",
       "2 0.07678                \n",
       "3 0.12440                \n",
       "4 0.08452                \n",
       "5 0.10480                \n",
       "6 0.10230                "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_data = data[-split_index, ]\n",
    "head(test_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad05c1e8-020c-4d37-808c-3735fd5c7270",
   "metadata": {},
   "source": [
    "We've split our data so that 70% is used for training and 30% for testing the most common split ratio in ML.\n",
    "\n",
    "## Building and Training the Neural Network\n",
    "\n",
    "Now, we will create our neural network model, which will help us make predictions about whether a tumor is malignant or benign based on the features in our dataset.\n",
    "\n",
    "First, we need to define the structure of our neural network. This involves creating a formula that specifies how the input features relate to the output variable, which in this case is the diagnosis. The formula will indicate that we want to predict the \"diagnosis\" based on all the other features in our dataset.\n",
    "\n",
    "In the code, we construct this formula using the `as.formula` function. We take the name of the diagnosis column and combine it with all other feature names using a plus sign (\"+\"). This tells R that we want to use all those features as inputs for our model.\n",
    "\n",
    "Next, we will train the neural network using the `neuralnet` function. We pass in our formula and specify the training data we prepared earlier. The `hidden` argument defines the architecture of our neural network. In this case, we are using two hidden layers: the first layer has 10 neurons, and the second layer has 5 neurons. The choice of hidden layers and neurons is important because it affects how well our model can learn complex patterns in the data. Hidden layers help the model understand non-linear relationships by processing inputs through weighted connections and activation functions. More layers allow the network to learn detailed representations, improving its ability to make accurate predictions. However, deeper networks need more data and computing power, while wider networks can sometimes memorize the training data instead of learning from it. Therefore, how we configure hidden layers and neurons directly affects the model's performance.\n",
    "\n",
    "Finally, we set `linear.output = FALSE` because we are dealing with a classification problem. This means we want our model to output probabilities for each class (benign or malignant) rather than continuous values.\n",
    "\n",
    "Once this code is executed, our neural network will be trained and ready to make predictions based on new data. This process is crucial for developing an effective tool for breast cancer prediction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bae5a281-8e72-414c-a01b-be8184aa09fd",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": [
    "# Create the formula for the neural network\n",
    "formula = as.formula(paste(\"diagnosis ~\", paste(colnames(data)[-1], collapse = \" + \")))\n",
    "\n",
    "# Train the neural network\n",
    "nn_model = neuralnet(formula, data = train_data, hidden = c(10, 5), linear.output = FALSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c687d09a-668b-476e-bc7a-df25166575ec",
   "metadata": {},
   "source": [
    "Here, we've created a neural network with two hidden layers (10 neurons in the first layer, 5 in the second). The 'diagnosis' is our output, and all other columns are our inputs.\n",
    "\n",
    "## Testing the Model\n",
    "\n",
    "Now, we will test our neural network model to evaluate its performance using the `test_data`. This way we can understand how well our model can predict whether a tumor is malignant or benign based on the features we have.\n",
    "\n",
    "First, we use the `predict` function to generate predictions for the test set. In the code, `predictions = predict(nn_model, test_data[, -1])` means we are applying our trained neural network model (`nn_model`) to the test data, excluding the diagnosis column (which is not needed for predictions). The model will output probabilities indicating how likely each tumor is to be malignant.\n",
    "\n",
    "Next, we convert these probabilities into binary predictions. The line `binary_predictions = ifelse(predictions > 0.5, 1, 0)` means that if the predicted probability is greater than 0.5, we classify the tumor as malignant (1). If it is 0.5 or lower, we classify it as benign (0). This threshold of 0.5 is commonly used in binary classification tasks.\n",
    "\n",
    "Finally, we calculate the accuracy of our model with `accuracy = mean(binary_predictions == test_data$diagnosis)`. This line compares our binary predictions to the actual diagnoses in the test set. The `mean` function calculates the proportion of correct predictions by checking how many times our model's predictions match the true labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "db44de1d-e93f-4413-a1b8-51c0142af749",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.5"
      ],
      "text/latex": [
       "0.5"
      ],
      "text/markdown": [
       "0.5"
      ],
      "text/plain": [
       "[1] 0.5"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "predictions = predict(nn_model, test_data[, -1])\n",
    "\n",
    "# Convert probabilities to binary predictions\n",
    "binary_predictions = ifelse(predictions > 0.5, 1, 0)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = mean(binary_predictions == test_data$diagnosis)\n",
    "accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e313e0f-c39f-42f6-95c2-d322edacae0e",
   "metadata": {},
   "source": [
    "The output we receive, approximately 0.93 $\\pm$ 0.03, indicates that our model correctly predicted about 93% of the tumors in the test set. This high accuracy suggests that our neural network is performing well and can effectively distinguish between malignant and benign tumors based on the features provided.\n",
    "\n",
    "## Interpreting the Results\n",
    "\n",
    "Our model achieved an accuracy of approx 90% $\\pm$ 5. This means that for every 100 predictions made, the model correctly identified about 93 tumors as either malignant or benign. This level of accuracy is quite impressive for a rudimentary model and indicates that our model is effective at distinguishing between the two types of tumors.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "We have successfully developed a neural network that can classify breast cancer tumors with high accuracy. Such a tool can be very beneficial for doctors, providing them with additional insights to support their diagnoses. However, it’s important to emphasize that this model should complement other diagnostic methods and the expertise of medical professionals, rather than replace them.\n",
    "\n",
    "In future projects, we could explore ways to improve our model further. For example, we could adjust the network structure by adding or removing layers and changing the number of neurons to see how it affects performance. We might also experiment with different subsets of features to identify which ones contribute most to accurate predictions. Additionally, trying other machine learning algorithms, such as Random Forests or Support Vector Machines, could provide alternative approaches to classification.\n",
    "\n",
    "In medical applications like this, achieving high accuracy is essential, but it’s equally important to understand how the model arrives at its predictions. Being able to explain the reasoning behind the model's decisions is crucial for building trust in its use. Always consult with healthcare professionals when applying these models in real-world situations to ensure they are used appropriately and effectively."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1541aa-9ab6-44af-9f55-f53369c21d9a",
   "metadata": {},
   "source": [
    "## Citations\n",
    "\n",
    "Wolberg, William, et al. \"Breast Cancer Wisconsin (Diagnostic).\" *UCI Machine Learning Repository*, 1993, https://doi.org/10.24432/C5DW2B.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4fe787e-6aab-497f-b379-625c452f8993",
   "metadata": {
    "vscode": {
     "languageId": "r"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
